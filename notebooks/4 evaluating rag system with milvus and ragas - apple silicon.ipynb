{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class RAG:\n",
    "    \"\"\"\n",
    "    RAG (Retrieval-Augmented Generation) class built upon Milvus and HuggingFace + MLX.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm, embedding_model, milvus_client: MilvusClient):\n",
    "        self._llm = llm\n",
    "        self._embedding_model = embedding_model\n",
    "        self._prepare_milvus(milvus_client)\n",
    "\n",
    "    def _emb_text(self, text: str) -> List[float]: # np.floatarray, actually\n",
    "        return self._embedding_model.encode([text])[0]\n",
    "\n",
    "    def _prepare_milvus(\n",
    "        self, milvus_client: MilvusClient, collection_name: str = \"rag_collection\"\n",
    "    ):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.collection_name = collection_name\n",
    "        if self.milvus_client.has_collection(self.collection_name):\n",
    "            self.milvus_client.drop_collection(self.collection_name)\n",
    "        embedding_dim = len(self._emb_text(\"foo\"))\n",
    "        self.milvus_client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            dimension=embedding_dim,\n",
    "            metric_type=\"IP\",  # Inner product distance\n",
    "            consistency_level=\"Strong\",  # Strong consistency level\n",
    "        )\n",
    "\n",
    "    def load(self, texts: List[str]):\n",
    "        \"\"\"\n",
    "        Load the text data into Milvus.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for i, line in enumerate(tqdm(texts, desc=\"Creating embeddings\")):\n",
    "            data.append({\"id\": i, \"vector\": self._emb_text(line), \"text\": line})\n",
    "\n",
    "        self.milvus_client.insert(collection_name=self.collection_name, data=data)\n",
    "\n",
    "    def retrieve(self, question: str, top_k: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve the most similar text data to the given question.\n",
    "        \"\"\"\n",
    "        search_res = self.milvus_client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            data=[self._emb_text(question)],\n",
    "            limit=top_k,\n",
    "            search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
    "            output_fields=[\"text\"],  # Return the text field\n",
    "        )\n",
    "        retrieved_texts = [res[\"entity\"][\"text\"] for res in search_res[0]]\n",
    "        return retrieved_texts[:top_k]\n",
    "\n",
    "    def answer(\n",
    "        self,\n",
    "        question: str,\n",
    "        retrieval_top_k: int = 3,\n",
    "        return_retrieved_text: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Answer the given question with the retrieved knowledge.\n",
    "        \"\"\"\n",
    "        retrieved_texts = self.retrieve(question, top_k=retrieval_top_k)\n",
    "        \n",
    "        user_prompt = USER_PROMPT.format(\n",
    "            context=\"\\n\".join(retrieved_texts), question=question\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=SYSTEM_PROMPT\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=user_prompt\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        res = self._llm.invoke(messages)\n",
    "\n",
    "        if not return_retrieved_text:\n",
    "            return res.content\n",
    "        else:\n",
    "            return res.content, retrieved_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts and Open Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n",
    "\"\"\"\n",
    "USER_PROMPT = \"\"\"\n",
    "Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client = MilvusClient(uri=\"./milvus_demo2.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Embedding Model and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d659b13ccc445296558f866af23963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import StaticEmbedding\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# embedding_tokenizer = Tokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "# static_embedding = StaticEmbedding(embedding_tokenizer, embedding_dim=1024)\n",
    "# embedding_model = SentenceTransformer(modules=[static_embedding])\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from mlx_lm import load\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/phi-4-4bit\")\n",
    "\n",
    "from langchain_community.llms.mlx_pipeline import MLXPipeline\n",
    "from langchain_community.chat_models.mlx import ChatMLX\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = MLXPipeline(\n",
    "    model=model, tokenizer=tokenizer, pipeline_kwargs={\"max_tokens\": 1024, \"temp\": 0.1}\n",
    ")\n",
    "\n",
    "chat = ChatMLX(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rag = RAG(llm=chat, embedding_model=embedding_model, milvus_client=milvus_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 384 [-3.81771475e-02  3.29111144e-02 -5.45937615e-03  1.43699432e-02\n",
      " -4.02910337e-02 -1.16532452e-01  3.16876508e-02  1.91175763e-03\n",
      " -4.26223613e-02  2.91681066e-02  4.24266979e-02  3.20417061e-02\n",
      "  2.98447404e-02  1.09803099e-02 -5.39396591e-02 -5.02772704e-02\n",
      " -2.35078186e-02  1.07793650e-02 -1.37707949e-01  4.11500549e-03\n",
      "  2.93330774e-02  6.68411553e-02 -1.53894098e-02  4.84376550e-02\n",
      " -8.81497413e-02 -1.27268368e-02  4.14090268e-02  4.08314951e-02\n",
      " -5.01558892e-02 -5.81250526e-02  4.88014929e-02  6.88901097e-02\n",
      "  5.87469302e-02  8.73099361e-03 -1.59182679e-02  8.51419792e-02\n",
      " -7.81474486e-02 -7.75167719e-02  2.07237769e-02  1.61942448e-02\n",
      "  3.25105898e-02 -5.34888841e-02 -6.22287765e-02 -2.43146457e-02\n",
      "  7.41276331e-03  2.39777416e-02  6.36097370e-03  5.11451066e-02\n",
      "  7.27667212e-02  3.46497037e-02 -5.47711030e-02 -5.93284741e-02\n",
      " -7.16696167e-03  2.01377142e-02  3.58463563e-02  5.59091382e-03\n",
      "  1.07735554e-02 -5.27637303e-02  1.01473741e-02 -8.73163342e-03\n",
      " -6.28155321e-02  3.84666845e-02 -1.39427204e-02  7.35259056e-02\n",
      "  9.00083110e-02 -7.99807459e-02 -1.63944960e-02  4.47223857e-02\n",
      " -6.88312650e-02 -3.30075696e-02 -1.53512163e-02  1.12996995e-02\n",
      "  3.64983343e-02  6.62666932e-02 -5.44066839e-02  8.79519898e-03\n",
      "  1.20745711e-02 -3.81696336e-02  6.86011976e-03  5.11235893e-02\n",
      "  7.74175972e-02 -1.22962646e-01  1.63531266e-02  4.95427325e-02\n",
      "  3.17454189e-02 -3.96687724e-02  1.70920731e-03  9.66940541e-03\n",
      " -3.25298905e-02 -3.39295268e-02 -1.33264616e-01  7.39704724e-03\n",
      " -1.02342814e-02  3.85915153e-02 -9.33099091e-02 -4.16540392e-02\n",
      "  6.98687136e-02 -2.62886230e-02 -1.49698213e-01  1.34353131e-01\n",
      "  3.75027657e-02  5.28785363e-02  4.49671485e-02  1.85995288e-02\n",
      "  5.44252284e-02  1.72716416e-02 -3.25182937e-02  4.60801944e-02\n",
      " -4.67377342e-02 -3.06096729e-02 -1.82268936e-02 -4.86957841e-02\n",
      "  3.28579582e-02 -3.92094953e-03  5.01056351e-02 -5.82454763e-02\n",
      " -1.00809373e-02  1.05502727e-02 -4.01561037e-02 -1.55400450e-03\n",
      "  6.08768575e-02 -4.55005765e-02  4.92598563e-02  2.61243414e-02\n",
      "  1.98505875e-02 -1.58545387e-03  5.95724434e-02 -6.51835862e-33\n",
      "  6.35851771e-02  3.06810206e-03  2.88844611e-02  1.73389703e-01\n",
      "  2.99481279e-03  2.76897065e-02 -9.51482579e-02 -3.11607793e-02\n",
      "  2.66698860e-02 -1.08712874e-02  2.39151940e-02  2.38443743e-02\n",
      " -3.12165227e-02  4.94056381e-02 -2.49787867e-02  1.01824269e-01\n",
      " -7.92783275e-02 -3.24872974e-03  4.30462547e-02  9.49330330e-02\n",
      " -6.65736422e-02  6.32926356e-03  2.22788807e-02  6.99767917e-02\n",
      " -7.53039541e-03 -1.74521771e-03  2.70446949e-02 -7.53242746e-02\n",
      "  1.14057794e-01  8.55988543e-03 -2.36879569e-02 -4.69805077e-02\n",
      "  1.43719018e-02  1.98206306e-02 -4.58438089e-03  1.37420697e-03\n",
      " -3.43194194e-02 -5.41234091e-02 -9.41645876e-02 -2.89598089e-02\n",
      " -1.87951308e-02  4.58199345e-02  4.75889966e-02 -3.19492235e-03\n",
      " -3.32171768e-02 -1.33891162e-02  5.10315485e-02  3.10757700e-02\n",
      "  1.53144775e-02  5.42222820e-02 -8.50554407e-02  1.33044831e-02\n",
      " -4.78141643e-02  7.10234269e-02 -1.31599624e-02 -2.42902641e-03\n",
      "  5.02184406e-02 -4.16093990e-02 -1.41695086e-02  3.23881879e-02\n",
      "  5.37519297e-03  9.12262499e-02  4.55124537e-03 -1.83422510e-02\n",
      " -1.52029991e-02 -4.63723540e-02  3.86707969e-02  1.46849891e-02\n",
      "  5.20024970e-02  1.90895272e-03 -1.49174305e-02  2.70289648e-02\n",
      "  3.12726051e-02  2.36842204e-02 -4.80394624e-03  3.61618511e-02\n",
      "  6.67887330e-02 -1.89081416e-03  2.13742647e-02 -5.76926470e-02\n",
      "  1.91577263e-02  3.15590687e-02 -1.84470434e-02 -4.07710373e-02\n",
      "  1.03958391e-01  1.19074993e-02 -1.49294641e-02 -1.05078436e-01\n",
      " -1.23710036e-02 -3.03939771e-04 -9.50324908e-02  5.83013184e-02\n",
      "  4.26109396e-02 -2.50124019e-02 -9.46091563e-02  4.00341527e-33\n",
      "  1.32172972e-01  5.45831257e-03 -3.31512764e-02 -9.10781175e-02\n",
      " -3.15739624e-02 -3.38864066e-02 -7.19889551e-02  1.25911906e-01\n",
      " -8.33933651e-02  5.27782179e-02  1.12826703e-03  2.19778046e-02\n",
      "  1.04063600e-01  1.29887508e-02  4.08715680e-02  1.87307149e-02\n",
      "  1.14286281e-01  2.48653349e-02  1.46103837e-02  6.18681498e-03\n",
      " -1.13734845e-02 -3.57009768e-02 -3.80397476e-02  1.11748576e-02\n",
      " -5.12898676e-02  7.88672455e-03  6.72205240e-02  3.40405828e-03\n",
      " -9.28479508e-02  3.70485224e-02 -2.22388208e-02  4.00781445e-02\n",
      " -3.07131894e-02 -1.14214113e-02 -1.44187007e-02  2.50452403e-02\n",
      " -9.75571722e-02 -3.53958495e-02 -3.75209972e-02 -1.00683998e-02\n",
      " -6.38862103e-02  2.54725404e-02  2.06223968e-02  3.76771502e-02\n",
      " -1.04281679e-01 -2.82806568e-02 -5.21058217e-02  1.28588621e-02\n",
      " -5.14237210e-02 -2.90379841e-02 -9.63978544e-02 -4.23606001e-02\n",
      "  6.70596883e-02 -3.07707023e-02 -1.03944233e-02  2.74102651e-02\n",
      " -2.80103944e-02  1.02891978e-02  4.30914573e-02  2.22976841e-02\n",
      "  8.01136438e-03  5.61470911e-02  4.08860408e-02  9.28760469e-02\n",
      "  1.65849216e-02 -5.38247712e-02  5.74163278e-04  5.07842936e-02\n",
      "  4.24875207e-02 -2.92068999e-02  9.23895836e-03 -1.06735807e-02\n",
      " -3.71527672e-02  2.36695306e-03 -3.03456709e-02  7.45052695e-02\n",
      "  2.62970943e-03 -1.76091325e-02  2.82069179e-03  3.83743010e-02\n",
      "  7.22763222e-03  4.56757396e-02  4.00427431e-02  1.42476391e-02\n",
      " -1.43160727e-02  5.86555190e-02  3.63530628e-02  5.52346408e-02\n",
      " -1.99883785e-02 -8.04462060e-02 -3.02477293e-02 -1.49129592e-02\n",
      "  2.22688299e-02  1.19625637e-02 -6.91014454e-02 -1.88070981e-08\n",
      " -7.85505176e-02  4.67108525e-02 -2.40804981e-02  6.34382740e-02\n",
      "  2.40138676e-02  1.43956405e-03 -9.08353627e-02 -6.68759048e-02\n",
      " -8.00782442e-02  5.66643849e-03  5.36583886e-02  1.04866259e-01\n",
      " -6.68804571e-02  1.54984677e-02  6.71185181e-02  7.08869323e-02\n",
      " -3.19899805e-02  2.08834801e-02 -2.19384190e-02 -7.26884510e-03\n",
      " -1.08125852e-02  4.08996409e-03  3.31555009e-02 -7.89784491e-02\n",
      "  3.87152322e-02 -7.53202513e-02 -1.58048682e-02  5.96065400e-03\n",
      "  5.19900071e-03 -6.14302717e-02  4.20057885e-02  9.53627899e-02\n",
      " -4.32334617e-02  1.43934563e-02 -1.06087439e-01 -2.79941838e-02\n",
      "  1.09661706e-02  6.95306957e-02  6.69809803e-02 -7.47754723e-02\n",
      " -7.85745829e-02  4.27465700e-02 -3.46037485e-02 -1.06056273e-01\n",
      " -3.56334858e-02  5.15012741e-02  6.86736181e-02 -4.99744713e-02\n",
      "  1.52898533e-02 -6.45573512e-02 -7.59339407e-02  2.61542965e-02\n",
      "  7.42642134e-02 -1.24497693e-02  1.33297861e-01  7.47663453e-02\n",
      "  5.12522422e-02  2.09902953e-02 -2.68759932e-02  8.89062583e-02\n",
      "  4.00210880e-02 -4.08902951e-02  3.18714082e-02  1.81631818e-02]\n"
     ]
    }
   ],
   "source": [
    "v = my_rag._emb_text(\"Hello, world!\")\n",
    "print(type(v), len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymilvus.milvus_client.milvus_client.MilvusClient object at 0x12bb65fd0>\n"
     ]
    }
   ],
   "source": [
    "print(my_rag.milvus_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_collection']\n"
     ]
    }
   ],
   "source": [
    "print(my_rag.milvus_client.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rag.retrieve(\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Vector Database with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 47/47 [00:00<00:00, 76.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/milvus-io/milvus/master/DEVELOPMENT.md\"\n",
    "file_path = \"./Milvus_DEVELOPMENT.md\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "with open(file_path, \"r\") as file:\n",
    "    file_text = file.read()\n",
    "\n",
    "# We simply use \"# \" to separate the content in the file, which can roughly separate the content of each main part of the markdown file.\n",
    "text_lines = file_text.split(\"# \")\n",
    "my_rag.load(text_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hardware Requirements\\n\\nThe following specification (either physical or virtual machine resources) is recommended for Milvus to build and run from source code.\\n\\n```\\n- 8GB of RAM\\n- 50GB of free disk space\\n```\\n\\n##',\n",
       " \"Software Requirements\\n\\nAll Linux distributions are available for Milvus development. However a majority of our contributor worked with Ubuntu or CentOS systems, with a small portion of Mac (both x86_64 and Apple Silicon) contributors. If you would like Milvus to build and run on other distributions, you are more than welcome to file an issue and contribute!\\n\\nHere's a list of verified OS types where Milvus can successfully build and run:\\n\\n- Debian/Ubuntu\\n- Amazon Linux\\n- MacOS (x86_64)\\n- MacOS (Apple Silicon)\\n\\n##\",\n",
       " 'Building Milvus on a local OS/shell environment\\n\\nThe details below outline the hardware and software requirements for building on Linux and MacOS.\\n\\n##']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is the hardware requirements specification if I want to build Milvus and run from source code?\"\n",
    "my_rag.retrieve(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n",
      "To build and run Milvus from source code, the recommended hardware requirements are:\n",
      "\n",
      "- 8GB of RAM\n",
      "- 50GB of free disk space\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('To build and run Milvus from source code, the recommended hardware requirements are:\\n\\n- 8GB of RAM\\n- 50GB of free disk space',\n",
       " ['Hardware Requirements\\n\\nThe following specification (either physical or virtual machine resources) is recommended for Milvus to build and run from source code.\\n\\n```\\n- 8GB of RAM\\n- 50GB of free disk space\\n```\\n\\n##',\n",
       "  \"Software Requirements\\n\\nAll Linux distributions are available for Milvus development. However a majority of our contributor worked with Ubuntu or CentOS systems, with a small portion of Mac (both x86_64 and Apple Silicon) contributors. If you would like Milvus to build and run on other distributions, you are more than welcome to file an issue and contribute!\\n\\nHere's a list of verified OS types where Milvus can successfully build and run:\\n\\n- Debian/Ubuntu\\n- Amazon Linux\\n- MacOS (x86_64)\\n- MacOS (Apple Silicon)\\n\\n##\",\n",
       "  'Building Milvus on a local OS/shell environment\\n\\nThe details below outline the hardware and software requirements for building on Linux and MacOS.\\n\\n##'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rag.answer(question, return_retrieved_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth\n",
    "Now let’s prepare some questions with its corresponding ground truth answers. We get answers and contexts from our RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  33%|███▎      | 1/3 [00:08<00:16,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build and run Milvus from source code, the recommended hardware specifications are:\n",
      "\n",
      "- 8GB of RAM\n",
      "- 50GB of free disk space\n",
      "\n",
      "These requirements are applicable for both physical and virtual machine resources.\n",
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  67%|██████▋   | 2/3 [00:12<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programming language used to write Knowhere is C++. This information is found in the context where it states, \"The algorithm library of Milvus, Knowhere is written in C++.\"\n",
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|██████████| 3/3 [00:17<00:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before running code coverage, it should be ensured that the code change is covered by unit tests. This is important to verify before submitting a pull request. The context specifies that developers should make sure their code change is covered by unit tests before proceeding with code coverage checks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the hardware requirements specificatio...</td>\n",
       "      <td>[Hardware Requirements\\n\\nThe following specif...</td>\n",
       "      <td>To build and run Milvus from source code, the ...</td>\n",
       "      <td>If you want to build Milvus and run from sourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the programming language used to write...</td>\n",
       "      <td>[Unless required by applicable law or agreed t...</td>\n",
       "      <td>The programming language used to write Knowher...</td>\n",
       "      <td>The programming language used to write Knowher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What should be ensured before running code cov...</td>\n",
       "      <td>[Code coverage\\n\\nBefore submitting your pull ...</td>\n",
       "      <td>Before running code coverage, it should be ens...</td>\n",
       "      <td>Before running code coverage, you should make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  what is the hardware requirements specificatio...   \n",
       "1  What is the programming language used to write...   \n",
       "2  What should be ensured before running code cov...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Hardware Requirements\\n\\nThe following specif...   \n",
       "1  [Unless required by applicable law or agreed t...   \n",
       "2  [Code coverage\\n\\nBefore submitting your pull ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  To build and run Milvus from source code, the ...   \n",
       "1  The programming language used to write Knowher...   \n",
       "2  Before running code coverage, it should be ens...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  If you want to build Milvus and run from sourc...  \n",
       "1  The programming language used to write Knowher...  \n",
       "2  Before running code coverage, you should make ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "question_list = [\n",
    "    \"what is the hardware requirements specification if I want to build Milvus and run from source code?\",\n",
    "    \"What is the programming language used to write Knowhere?\",\n",
    "    \"What should be ensured before running code coverage?\",\n",
    "]\n",
    "ground_truth_list = [\n",
    "    \"If you want to build Milvus and run from source code, the recommended hardware requirements specification is:\\n\\n- 8GB of RAM\\n- 50GB of free disk space.\",\n",
    "    \"The programming language used to write Knowhere is C++.\",\n",
    "    \"Before running code coverage, you should make sure that your code changes are covered by unit tests.\",\n",
    "]\n",
    "contexts_list = []\n",
    "answer_list = []\n",
    "for question in tqdm(question_list, desc=\"Answering questions\"):\n",
    "    answer, contexts = my_rag.answer(question, return_retrieved_text=True)\n",
    "    contexts_list.append(contexts)\n",
    "    answer_list.append(answer)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": question_list,\n",
    "        \"contexts\": contexts_list,\n",
    "        \"answer\": answer_list,\n",
    "        \"ground_truth\": ground_truth_list,\n",
    "    }\n",
    ")\n",
    "rag_results = Dataset.from_pandas(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is the hardware requirements specification if I want to build Milvus and run from source code?',\n",
       " 'contexts': ['Hardware Requirements\\n\\nThe following specification (either physical or virtual machine resources) is recommended for Milvus to build and run from source code.\\n\\n```\\n- 8GB of RAM\\n- 50GB of free disk space\\n```\\n\\n##',\n",
       "  \"Software Requirements\\n\\nAll Linux distributions are available for Milvus development. However a majority of our contributor worked with Ubuntu or CentOS systems, with a small portion of Mac (both x86_64 and Apple Silicon) contributors. If you would like Milvus to build and run on other distributions, you are more than welcome to file an issue and contribute!\\n\\nHere's a list of verified OS types where Milvus can successfully build and run:\\n\\n- Debian/Ubuntu\\n- Amazon Linux\\n- MacOS (x86_64)\\n- MacOS (Apple Silicon)\\n\\n##\",\n",
       "  'Building Milvus on a local OS/shell environment\\n\\nThe details below outline the hardware and software requirements for building on Linux and MacOS.\\n\\n##'],\n",
       " 'answer': 'To build and run Milvus from source code, the recommended hardware specifications are:\\n\\n- 8GB of RAM\\n- 50GB of free disk space\\n\\nThese requirements are applicable for both physical and virtual machine resources.',\n",
       " 'ground_truth': 'If you want to build Milvus and run from source code, the recommended hardware requirements specification is:\\n\\n- 8GB of RAM\\n- 50GB of free disk space.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "what is the hardware requirements specification if I want to build Milvus and run from source code?\n"
     ]
    }
   ],
   "source": [
    "print(type(sample.user_input))\n",
    "print(sample.user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with RAGAS: Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n",
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample \n",
    "from ragas.metrics import Faithfulness\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=rag_results[0]['question'],\n",
    "        response=rag_results[0]['answer'],\n",
    "        retrieved_contexts=rag_results[0]['contexts']\n",
    "    )\n",
    "\n",
    "llm_wrapped = LangchainLLMWrapper(chat)\n",
    "scorer = Faithfulness(llm=llm_wrapped)\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
